{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "This notebook will go over a how to use propensity_scores in mr_uplift packages.The main change is that builds a random forest of the form $t = f(x)$ for the propensity model. It them predicts and calculates the inverse probability as the observation weight:  1/f(x). Note that the propensity model is a multi-classification model and supports more than two treatments. This weight is then fed into both the ERUPT calculations and loss functions of the uplift model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from mr_uplift.dataset.data_simulation import get_observational_uplift_data_2\n",
    "from mr_uplift.mr_uplift import MRUplift, get_t_data\n",
    "from mr_uplift.keras_model_functionality import prepare_data_optimized_loss\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generating Process\n",
    "\n",
    "Below is the data generating process of the data. This is similar to the previous data function except that the treatment assignment is a function of the explanatory variable $x_1$. This should simulate a more observational scenario.\n",
    "\n",
    "\\begin{equation}\n",
    "x_1  \\sim runif(0,1)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "x_2 \\sim runif(0,1)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "t \\sim rbinom(.2+I(x_1>0)*.6 )\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "noise \\sim rnorm(0,1)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "y = x_1*t + noise\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Below the data is generated and two models are built. The first is an uplift model using MSE loss and does not weight observations based on explanatory variables. The second is an uplift model that uses the optimized loss with observations weighted by the propensity model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
   ],
   "source": [
    "y, x, t = get_observational_uplift_data_2(10000)\n",
    "\n",
    "y = y[:,0].reshape(-1,1)\n",
    "uplift_model = MRUplift()\n",
    "param_grid = dict(num_nodes=[8,64], dropout=[.1, .5], activation=[\n",
    "                          'relu'], num_layers=[1], epochs=[25], batch_size=[512])\n",
    "\n",
    "uplift_model.fit(x, y, t.reshape(-1,1), \n",
    "                 param_grid = param_grid, n_jobs = 1)\n",
    "\n",
    "uplift_model_propensity = MRUplift()\n",
    "param_grid_propensity = dict(num_nodes=[8, 64], dropout=[.1, .5], activation=[\n",
    "                          'relu'], num_layers=[1], epochs=[25], batch_size=[512],\n",
    "                 alpha = [.9999,.99], copy_several_times = [1])\n",
    "\n",
    "uplift_model_propensity.fit(x, y, t.reshape(-1,1), \n",
    "                 param_grid = param_grid_propensity, n_jobs = 1,\n",
    "                optimized_loss = True, use_propensity = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate oos predictions \n",
    "\n",
    "y_test, x_test, t_test = get_observational_uplift_data_2(10000)\n",
    "\n",
    "pred_uplift = uplift_model.predict_optimal_treatments(x = x_test)\n",
    "pred_uplift_propensity = uplift_model_propensity.predict_optimal_treatments(x = x_test, \n",
    "                use_propensity_score_cutoff = True)\n",
    "correct_tmt = (x_test[:,0]>0).reshape(-1,1)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FInally the cells below compare the estimated optimal decisions with correct ones for both models. Note that the propensity mdoel correctly identifies optimal treatment for 58% of observations while the standard model only identifies 66% of observations correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplift Model Correct Decisions\n",
      "0.5754\n",
      "Uplift Model using Propensity Correct Decisions\n",
      "0.9886\n"
     ]
    }
   ],
   "source": [
    "print('Uplift Model Correct Decisions')\n",
    "print((pred_uplift == correct_tmt).mean())\n",
    "\n",
    "print('Uplift Model using Propensity Correct Decisions')\n",
    "print((pred_uplift_propensity == correct_tmt).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I calculate the estimated expected responses under propoposed treatments vs actual for both models. \n",
    "\n",
    "Without the propensity model the estimate ERUPT is ~.018 which is higher than the actual response under proposed treatments of .06. \n",
    "\n",
    "With the propensity model the ERUPT metric is much closer to actual treatments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Test Data Set\n",
      "(       mean       std response_var_names weights assignment treatment\n",
      "0  0.018898  0.001978              var_0       1      model        -1\n",
      "0  0.008591  0.002204              var_0       1     random        -1\n",
      "0 -0.001738  0.001734              var_0      -1        ate       0.0\n",
      "0  0.150436  0.004449              var_0      -1        ate       1.0,    num_observations  tmt weights  percent_tmt\n",
      "0              6433  0.0       1        0.919\n",
      "1               567  1.0       1        0.081)\n",
      "Actual Estimate of Gains for Uplift Model\n",
      "0.01450183238033326\n"
     ]
    }
   ],
   "source": [
    "#Estimated uplift vs actual \n",
    "print(uplift_model.get_erupt_curves())\n",
    "\n",
    "print('Actual Estimate of Gains for Uplift Model')\n",
    "print((pred_uplift*x_test[:,0].reshape(-1,1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Test Data Set\n",
      "(       mean       std response_var_names weights assignment treatment\n",
      "0  0.127240  0.002598              var_0       1      model        -1\n",
      "0  0.001792  0.004851              var_0       1     random        -1\n",
      "0 -0.001134  0.002104              var_0      -1        ate       0.0\n",
      "0  0.010204  0.006303              var_0      -1        ate       1.0,    num_observations  tmt weights  percent_tmt\n",
      "0              3658  1.0       1     0.522571\n",
      "1              3342  0.0       1     0.477429)\n",
      "Actual Estimate of Gains for Uplift Model with propensity scores\n",
      "0.1262029577145106\n"
     ]
    }
   ],
   "source": [
    "#Estimated uplift with propensity vs actual \n",
    "print(uplift_model_propensity.get_erupt_curves())\n",
    "\n",
    "print('Actual Estimate of Gains for Uplift Model with propensity scores')\n",
    "print((pred_uplift_propensity*x_test[:,0].reshape(-1,1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical Best\n",
      "0.12626648857998107\n"
     ]
    }
   ],
   "source": [
    "print('Theoretical Best')\n",
    "print((correct_tmt*x_test[:,0].reshape(-1,1)).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
